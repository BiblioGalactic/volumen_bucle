autoconversation_ZH.sh

与 Mistral 的对话脚本

此脚本通过 llama-cli 与 Mistral 语言模型交互，以生成富有同理心且真实的对话。它结合了人工智能的创造力与一个随机短语生成系统，该系统包括主语、动词、动作、补语和情感，从而实现更人性化和多样化的对话。此外，脚本会保留交互历史，并自动管理临时文件，确保工作流程干净、安全。

功能

该脚本通过精心挑选的语言元素组合生成随机句子，以传递情感和上下文。每次执行都会产生新的句子，并将其保存到一个记忆文件（MEMORIA），从而使模型能够参考历史记录并生成连贯且具有上下文的响应。

每次执行会进行两轮交互：第一轮生成初始句子并获取模型的响应；第二轮利用对话历史来创建连续性并加深对话内容。

执行过程中生成的所有临时文件在结束时将自动删除，避免数据累积并保持环境干净（TEMP_DIR）。

使用方法

首先，通过 chmod +x autoconversacion.sh 将脚本设为可执行文件。  
然后在终端中运行 ./autoconversacion.sh。  

执行期间，脚本会请求必要路径以确保正确运行：模型位置（MODELO_PATH）、可执行文件路径（MAIN_BINARY）、对话记忆文件（MEMORIA）以及临时目录（TEMP_DIR）。  

执行完成后，你可以直接在终端查看生成的对话，并在记忆文件中查看完整历史。这有助于保持对话的连续性并在未来的执行中复用数据。

系统要求

该脚本设计用于 macOS，并需 Bash 5 或更高版本。  
需要具备 .gguf 格式的 Mistral 模型以及正确编译并可运行的 llama-cli。  
建议拥有足够的 CPU 和内存资源，以便模型在长时间会话中高效处理提示。

补充说明

此脚本特别适用于文本生成实验、对话模拟、语言模型测试以及互动内容创作。  
建议定期检查记忆文件以评估连贯性，并根据需要在 llama-cli 中调整生成参数。  
模块化设计使得你可以扩展短语生成功能，添加新的主语、动词或情感，而不必修改核心逻辑。
