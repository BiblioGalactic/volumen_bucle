# ğŸ§  bucleia â€“ Selfâ€‘generative AI in Local Loop

This script allows you to launch a local model (based on `llama.cpp`) with **autoâ€‘synthetic** behaviour:
the AI starts from a single initial instruction (`loop_prompt.txt`) and evolves autonomously, rewriting its own input (`nexus.txt`) after each execution.

## âš™ï¸ What does it do?

* Runs a `.gguf` model using a combined prompt of the system and the last generated input.
* Filters the output to capture only the useful block generated by the AI (between `[[` and `]]`).
* Automatically rewrites the input file (`nexus.txt`) with the generated response.
* Saves a complete copy of each session in `sesiones/` and full logs in `logs/`.

> Each time it runs, the system feeds back on itself: **the AI instructs itself** from its own previous output.

## ğŸ“ Expected structure

In the same directory as the `loopai.sh` script there must be the following files:

* `llama-cli` â†’ binary from `llama.cpp`
* `mistral-7b-instruct-v0.1.Q6_K.gguf` â†’ local model
* `loop_prompt.txt` â†’ system initial prompt
* `nexus.txt` â†’ first input, overwritten with each response

And they will be generated automatically:

* `sesiones/` â†’ .md copies of each generated session
* `logs/` â†’ complete execution logs

## ğŸ§ª Requirements

* Bash (macOS / Linux)
* Compiled `llama.cpp`
* A compatible `.gguf` model

## ğŸš€ Execution

```bash
chmod +x loopai.sh
./loopai.sh
```

## ğŸ’¡ Creative use

Ideal for loop simulations, autonomous narrative agents or AI experiments that need to evolve without external intervention.
Designed for offline, reproducible and fully local environments.

---

Created by **Eto Demerzel**

**Eto Demerzel** (Gustavo Silva Da Costa)
https://etodemerzel.gumroad.com  
https://github.com/BiblioGalactic
