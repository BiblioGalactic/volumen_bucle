# 🧠 bucleia – 本地循环中的自生成 AI

该脚本允许启动一个具有 **自合成** 行为的本地模型（基于 `llama.cpp`）：
AI 从一个单一的初始指令（`循环提示.txt`）出发，自动演化，在每次执行后重写自己的输入（`连接.txt`）。

## ⚙️ 功能

* 使用系统提示和上一次生成的输入组合的提示来运行 `.gguf` 模型。
* 过滤输出，只捕获 AI 生成的有用块（在 `[[` 和 `]]` 之间）。
* 使用生成的回应自动重写输入文件（`连接.txt`）。
* 在 `sesiones/` 中保存每个会话的完整副本，在 `logs/` 中保存完整日志。

> 每次运行时，系统都会进行自我反馈：**AI 根据自己的先前输出指导自己**。

## 📁 预期结构

在 `循环AI.sh` 脚本所在目录中应有以下文件：

* `llama-cli` → 来自 `llama.cpp` 的二进制文件
* `mistral-7b-instruct-v0.1.Q6_K.gguf` → 本地模型
* `循环提示.txt` → 系统初始提示
* `连接.txt` → 第一个输入，每次回应后被覆盖

并且会自动生成：

* `sesiones/` → 每个生成会话的 .md 副本
* `logs/` → 完整的执行日志

## 🧪 要求

* Bash（macOS / Linux）
* 已编译的 `llama.cpp`
* 兼容的 `.gguf` 模型

## 🚀 执行

```bash
chmod +x 循环AI.sh
./循环AI.sh
```

## 💡 创意用途

非常适合循环模拟、自主叙事代理或需要在没有外部干预情况下演化的 AI 实验。
专为离线、可复现且完全本地的环境而设计。

---

由 **Eto Demerzel** 创建
